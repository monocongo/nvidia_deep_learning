{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-atf3gekcgR"
   },
   "source": [
    "# Assessment 1: I can train and deploy a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7wkT17FkmU6"
   },
   "source": [
    "At this point, you've worked through a full deep learning workflow. You've loaded a dataset, trained a model, and deployed your model into a simple application. Validate your learning by attempting to replicate that workflow with a new problem.\n",
    "\n",
    "We've included a dataset which consists of two classes:  \n",
    "\n",
    "1) Face: Contains images which include the face of a whale  \n",
    "2) Not Face: Contains images which do not include the face of a whale.  \n",
    "\n",
    "The dataset is located at ```/dli/data/whale/data/train```.\n",
    "\n",
    "Your challenge is:\n",
    "\n",
    "1) Use [DIGITS](/digits) to train a model to identify *new* whale faces with an accuracy of more than 80%.   \n",
    "\n",
    "2) Deploy your model by modifying and saving the python application [submission.py](../../../../edit/tasks/task-assessment/task/submission.py) to return the word \"whale\" if the image contains a whale's face and \"not whale\" if the image does not.  \n",
    "\n",
    "Resources:\n",
    "\n",
    "1) [Train a model](../../task1/task/Train%20a%20Model.ipynb)  \n",
    "2) [New Data as a goal](../../task2/task/New%20Data%20as%20a%20Goal.ipynb)  \n",
    "3) [Deployment](../../task3/task/Deployment.ipynb)  \n",
    "\n",
    "Suggestions: \n",
    "\n",
    "- Use empty code blocks to find out any informantion necessary to solve this problem: eg: ```!ls [directorypath] prints the files in a given directory``` \n",
    "- Executing the first two cells below will run your python script with test images, the first should return \"whale\" and the second should return \"not whale\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaaY1Vb3o3mC"
   },
   "source": [
    "Start in [DIGITS](/digits/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0827 19:12:35.069412   212 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0827 19:12:35.070190   212 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0827 19:12:35.070271   212 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0827 19:12:35.070406   212 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0827 19:12:35.070430   212 _caffe.cpp:175] Net('/dli/data/digits/20190827-183652-8454/deploy.prototxt', 1, weights='/dli/data/digits/20190827-183652-8454/snapshot_iter_1080.caffemodel')\n",
      "I0827 19:12:35.070788   212 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190827-183652-8454/deploy.prototxt\n",
      "I0827 19:12:35.070822   212 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0827 19:12:35.070832   212 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0827 19:12:35.080904   212 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0827 19:12:35.081315   212 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0827 19:12:35.081332   212 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0827 19:12:35.081346   212 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0827 19:12:35.081363   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.081385   212 net.cpp:199] Created Layer input (0)\n",
      "I0827 19:12:35.081401   212 net.cpp:541] input -> data\n",
      "I0827 19:12:35.082206   212 net.cpp:259] Setting up input\n",
      "I0827 19:12:35.082237   212 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0827 19:12:35.082258   212 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0827 19:12:35.082274   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.082326   212 net.cpp:199] Created Layer conv1 (1)\n",
      "I0827 19:12:35.082340   212 net.cpp:571] conv1 <- data\n",
      "I0827 19:12:35.082353   212 net.cpp:541] conv1 -> conv1\n",
      "I0827 19:12:35.632941   212 net.cpp:259] Setting up conv1\n",
      "I0827 19:12:35.633004   212 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0827 19:12:35.633044   212 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0827 19:12:35.633065   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.633090   212 net.cpp:199] Created Layer relu1 (2)\n",
      "I0827 19:12:35.633105   212 net.cpp:571] relu1 <- conv1\n",
      "I0827 19:12:35.633118   212 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0827 19:12:35.633157   212 net.cpp:259] Setting up relu1\n",
      "I0827 19:12:35.633173   212 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0827 19:12:35.633185   212 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0827 19:12:35.633200   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.633234   212 net.cpp:199] Created Layer norm1 (3)\n",
      "I0827 19:12:35.633247   212 net.cpp:571] norm1 <- conv1\n",
      "I0827 19:12:35.633257   212 net.cpp:541] norm1 -> norm1\n",
      "I0827 19:12:35.633332   212 net.cpp:259] Setting up norm1\n",
      "I0827 19:12:35.633350   212 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0827 19:12:35.633365   212 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0827 19:12:35.633380   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.633436   212 net.cpp:199] Created Layer pool1 (4)\n",
      "I0827 19:12:35.633451   212 net.cpp:571] pool1 <- norm1\n",
      "I0827 19:12:35.633469   212 net.cpp:541] pool1 -> pool1\n",
      "I0827 19:12:35.633536   212 net.cpp:259] Setting up pool1\n",
      "I0827 19:12:35.633554   212 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0827 19:12:35.633569   212 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0827 19:12:35.633584   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.633623   212 net.cpp:199] Created Layer conv2 (5)\n",
      "I0827 19:12:35.633638   212 net.cpp:571] conv2 <- pool1\n",
      "I0827 19:12:35.633651   212 net.cpp:541] conv2 -> conv2\n",
      "I0827 19:12:35.640777   212 net.cpp:259] Setting up conv2\n",
      "I0827 19:12:35.640808   212 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0827 19:12:35.640835   212 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0827 19:12:35.640849   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.640858   212 net.cpp:199] Created Layer relu2 (6)\n",
      "I0827 19:12:35.640869   212 net.cpp:571] relu2 <- conv2\n",
      "I0827 19:12:35.640888   212 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0827 19:12:35.640910   212 net.cpp:259] Setting up relu2\n",
      "I0827 19:12:35.640928   212 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0827 19:12:35.640939   212 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0827 19:12:35.640954   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.640974   212 net.cpp:199] Created Layer norm2 (7)\n",
      "I0827 19:12:35.640987   212 net.cpp:571] norm2 <- conv2\n",
      "I0827 19:12:35.641003   212 net.cpp:541] norm2 -> norm2\n",
      "I0827 19:12:35.641058   212 net.cpp:259] Setting up norm2\n",
      "I0827 19:12:35.641077   212 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0827 19:12:35.641088   212 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0827 19:12:35.641104   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.641120   212 net.cpp:199] Created Layer pool2 (8)\n",
      "I0827 19:12:35.641134   212 net.cpp:571] pool2 <- norm2\n",
      "I0827 19:12:35.641144   212 net.cpp:541] pool2 -> pool2\n",
      "I0827 19:12:35.641208   212 net.cpp:259] Setting up pool2\n",
      "I0827 19:12:35.641225   212 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0827 19:12:35.641239   212 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0827 19:12:35.641254   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.641275   212 net.cpp:199] Created Layer conv3 (9)\n",
      "I0827 19:12:35.641288   212 net.cpp:571] conv3 <- pool2\n",
      "I0827 19:12:35.641300   212 net.cpp:541] conv3 -> conv3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0827 19:12:35.657299   212 net.cpp:259] Setting up conv3\n",
      "I0827 19:12:35.657335   212 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0827 19:12:35.657371   212 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0827 19:12:35.657387   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.657405   212 net.cpp:199] Created Layer relu3 (10)\n",
      "I0827 19:12:35.657416   212 net.cpp:571] relu3 <- conv3\n",
      "I0827 19:12:35.657428   212 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0827 19:12:35.657449   212 net.cpp:259] Setting up relu3\n",
      "I0827 19:12:35.657467   212 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0827 19:12:35.657479   212 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0827 19:12:35.657493   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.657519   212 net.cpp:199] Created Layer conv4 (11)\n",
      "I0827 19:12:35.657531   212 net.cpp:571] conv4 <- conv3\n",
      "I0827 19:12:35.657541   212 net.cpp:541] conv4 -> conv4\n",
      "I0827 19:12:35.670209   212 net.cpp:259] Setting up conv4\n",
      "I0827 19:12:35.670243   212 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0827 19:12:35.670302   212 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0827 19:12:35.670320   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.670334   212 net.cpp:199] Created Layer relu4 (12)\n",
      "I0827 19:12:35.670351   212 net.cpp:571] relu4 <- conv4\n",
      "I0827 19:12:35.670363   212 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0827 19:12:35.670385   212 net.cpp:259] Setting up relu4\n",
      "I0827 19:12:35.670403   212 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0827 19:12:35.670419   212 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0827 19:12:35.670430   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.670460   212 net.cpp:199] Created Layer conv5 (13)\n",
      "I0827 19:12:35.670473   212 net.cpp:571] conv5 <- conv4\n",
      "I0827 19:12:35.670485   212 net.cpp:541] conv5 -> conv5\n",
      "I0827 19:12:35.678763   212 net.cpp:259] Setting up conv5\n",
      "I0827 19:12:35.678791   212 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0827 19:12:35.678820   212 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0827 19:12:35.678834   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.678843   212 net.cpp:199] Created Layer relu5 (14)\n",
      "I0827 19:12:35.678854   212 net.cpp:571] relu5 <- conv5\n",
      "I0827 19:12:35.678866   212 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0827 19:12:35.678881   212 net.cpp:259] Setting up relu5\n",
      "I0827 19:12:35.678894   212 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0827 19:12:35.678905   212 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0827 19:12:35.678915   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.678932   212 net.cpp:199] Created Layer pool5 (15)\n",
      "I0827 19:12:35.678942   212 net.cpp:571] pool5 <- conv5\n",
      "I0827 19:12:35.678953   212 net.cpp:541] pool5 -> pool5\n",
      "I0827 19:12:35.679023   212 net.cpp:259] Setting up pool5\n",
      "I0827 19:12:35.679039   212 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0827 19:12:35.679051   212 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0827 19:12:35.679064   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:35.679075   212 net.cpp:199] Created Layer fc6 (16)\n",
      "I0827 19:12:35.679086   212 net.cpp:571] fc6 <- pool5\n",
      "I0827 19:12:35.679093   212 net.cpp:541] fc6 -> fc6\n",
      "I0827 19:12:36.378552   212 net.cpp:259] Setting up fc6\n",
      "I0827 19:12:36.378607   212 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0827 19:12:36.378630   212 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0827 19:12:36.378645   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:36.378660   212 net.cpp:199] Created Layer relu6 (17)\n",
      "I0827 19:12:36.378674   212 net.cpp:571] relu6 <- fc6\n",
      "I0827 19:12:36.378684   212 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0827 19:12:36.378707   212 net.cpp:259] Setting up relu6\n",
      "I0827 19:12:36.378720   212 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0827 19:12:36.378726   212 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0827 19:12:36.378737   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:36.378751   212 net.cpp:199] Created Layer drop6 (18)\n",
      "I0827 19:12:36.378762   212 net.cpp:571] drop6 <- fc6\n",
      "I0827 19:12:36.378767   212 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0827 19:12:36.413413   212 net.cpp:259] Setting up drop6\n",
      "I0827 19:12:36.413463   212 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0827 19:12:36.413476   212 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0827 19:12:36.413489   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:36.413512   212 net.cpp:199] Created Layer fc7 (19)\n",
      "I0827 19:12:36.413558   212 net.cpp:571] fc7 <- fc6\n",
      "I0827 19:12:36.413579   212 net.cpp:541] fc7 -> fc7\n",
      "I0827 19:12:36.724889   212 net.cpp:259] Setting up fc7\n",
      "I0827 19:12:36.724957   212 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0827 19:12:36.724994   212 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0827 19:12:36.725014   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:36.725029   212 net.cpp:199] Created Layer relu7 (20)\n",
      "I0827 19:12:36.725040   212 net.cpp:571] relu7 <- fc7\n",
      "I0827 19:12:36.725052   212 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0827 19:12:36.725076   212 net.cpp:259] Setting up relu7\n",
      "I0827 19:12:36.725087   212 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0827 19:12:36.725103   212 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0827 19:12:36.725119   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:36.725142   212 net.cpp:199] Created Layer drop7 (21)\n",
      "I0827 19:12:36.725152   212 net.cpp:571] drop7 <- fc7\n",
      "I0827 19:12:36.725158   212 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0827 19:12:36.759934   212 net.cpp:259] Setting up drop7\n",
      "I0827 19:12:36.759984   212 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0827 19:12:36.760007   212 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0827 19:12:36.760026   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:36.760059   212 net.cpp:199] Created Layer fc8 (22)\n",
      "I0827 19:12:36.760077   212 net.cpp:571] fc8 <- fc7\n",
      "I0827 19:12:36.760093   212 net.cpp:541] fc8 -> fc8\n",
      "I0827 19:12:36.761210   212 net.cpp:259] Setting up fc8\n",
      "I0827 19:12:36.761238   212 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0827 19:12:36.761266   212 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0827 19:12:36.761281   212 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:36.761301   212 net.cpp:199] Created Layer softmax (23)\n",
      "I0827 19:12:36.761312   212 net.cpp:571] softmax <- fc8\n",
      "I0827 19:12:36.761318   212 net.cpp:541] softmax -> softmax\n",
      "I0827 19:12:36.761410   212 net.cpp:259] Setting up softmax\n",
      "I0827 19:12:36.761426   212 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0827 19:12:36.761435   212 net.cpp:337] softmax does not need backward computation.\n",
      "I0827 19:12:36.761445   212 net.cpp:337] fc8 does not need backward computation.\n",
      "I0827 19:12:36.761451   212 net.cpp:337] drop7 does not need backward computation.\n",
      "I0827 19:12:36.761461   212 net.cpp:337] relu7 does not need backward computation.\n",
      "I0827 19:12:36.761467   212 net.cpp:337] fc7 does not need backward computation.\n",
      "I0827 19:12:36.761477   212 net.cpp:337] drop6 does not need backward computation.\n",
      "I0827 19:12:36.761482   212 net.cpp:337] relu6 does not need backward computation.\n",
      "I0827 19:12:36.761493   212 net.cpp:337] fc6 does not need backward computation.\n",
      "I0827 19:12:36.761500   212 net.cpp:337] pool5 does not need backward computation.\n",
      "I0827 19:12:36.761507   212 net.cpp:337] relu5 does not need backward computation.\n",
      "I0827 19:12:36.761513   212 net.cpp:337] conv5 does not need backward computation.\n",
      "I0827 19:12:36.761523   212 net.cpp:337] relu4 does not need backward computation.\n",
      "I0827 19:12:36.761529   212 net.cpp:337] conv4 does not need backward computation.\n",
      "I0827 19:12:36.761541   212 net.cpp:337] relu3 does not need backward computation.\n",
      "I0827 19:12:36.761555   212 net.cpp:337] conv3 does not need backward computation.\n",
      "I0827 19:12:36.761570   212 net.cpp:337] pool2 does not need backward computation.\n",
      "I0827 19:12:36.761582   212 net.cpp:337] norm2 does not need backward computation.\n",
      "I0827 19:12:36.761592   212 net.cpp:337] relu2 does not need backward computation.\n",
      "I0827 19:12:36.761620   212 net.cpp:337] conv2 does not need backward computation.\n",
      "I0827 19:12:36.761632   212 net.cpp:337] pool1 does not need backward computation.\n",
      "I0827 19:12:36.761672   212 net.cpp:337] norm1 does not need backward computation.\n",
      "I0827 19:12:36.761682   212 net.cpp:337] relu1 does not need backward computation.\n",
      "I0827 19:12:36.761693   212 net.cpp:337] conv1 does not need backward computation.\n",
      "I0827 19:12:36.761704   212 net.cpp:337] input does not need backward computation.\n",
      "I0827 19:12:36.761714   212 net.cpp:379] This network produces output softmax\n",
      "I0827 19:12:36.761744   212 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0827 19:12:36.761756   212 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0827 19:12:36.761768   212 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0827 19:12:36.761773   212 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0827 19:12:36.761783   212 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0827 19:12:36.761788   212 net.cpp:420] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0827 19:12:36.893735   212 net.cpp:1129] Ignoring source layer train-data\n",
      "I0827 19:12:36.893781   212 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0827 19:12:36.893919   212 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0827 19:12:36.893935   212 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0827 19:12:36.893944   212 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0827 19:12:36.893954   212 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0827 19:12:36.894181   212 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0827 19:12:36.894197   212 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0827 19:12:36.894207   212 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0827 19:12:36.894219   212 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0827 19:12:36.894806   212 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0827 19:12:36.894822   212 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0827 19:12:36.895270   212 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0827 19:12:36.895287   212 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0827 19:12:36.895596   212 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0827 19:12:36.895612   212 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0827 19:12:36.895620   212 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0827 19:12:36.918215   212 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0827 19:12:36.918256   212 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0827 19:12:36.918262   212 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0827 19:12:36.928488   212 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0827 19:12:36.928525   212 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0827 19:12:36.928531   212 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0827 19:12:36.928561   212 net.cpp:1129] Ignoring source layer loss\n",
      "whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/face/w_1.jpg'  #This should return \"whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0827 19:12:45.481096   227 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0827 19:12:45.481917   227 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0827 19:12:45.482008   227 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0827 19:12:45.482143   227 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0827 19:12:45.482161   227 _caffe.cpp:175] Net('/dli/data/digits/20190827-183652-8454/deploy.prototxt', 1, weights='/dli/data/digits/20190827-183652-8454/snapshot_iter_1080.caffemodel')\n",
      "I0827 19:12:45.482578   227 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190827-183652-8454/deploy.prototxt\n",
      "I0827 19:12:45.482610   227 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0827 19:12:45.482620   227 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0827 19:12:45.493173   227 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0827 19:12:45.493728   227 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0827 19:12:45.493747   227 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0827 19:12:45.493760   227 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0827 19:12:45.493778   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:45.493806   227 net.cpp:199] Created Layer input (0)\n",
      "I0827 19:12:45.493822   227 net.cpp:541] input -> data\n",
      "I0827 19:12:45.494607   227 net.cpp:259] Setting up input\n",
      "I0827 19:12:45.494639   227 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0827 19:12:45.494662   227 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0827 19:12:45.494675   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:45.494724   227 net.cpp:199] Created Layer conv1 (1)\n",
      "I0827 19:12:45.494738   227 net.cpp:571] conv1 <- data\n",
      "I0827 19:12:45.494752   227 net.cpp:541] conv1 -> conv1\n",
      "I0827 19:12:46.048727   227 net.cpp:259] Setting up conv1\n",
      "I0827 19:12:46.048789   227 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0827 19:12:46.048818   227 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0827 19:12:46.048837   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.048859   227 net.cpp:199] Created Layer relu1 (2)\n",
      "I0827 19:12:46.048872   227 net.cpp:571] relu1 <- conv1\n",
      "I0827 19:12:46.048884   227 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0827 19:12:46.048911   227 net.cpp:259] Setting up relu1\n",
      "I0827 19:12:46.048924   227 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0827 19:12:46.048931   227 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0827 19:12:46.048939   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.048962   227 net.cpp:199] Created Layer norm1 (3)\n",
      "I0827 19:12:46.048974   227 net.cpp:571] norm1 <- conv1\n",
      "I0827 19:12:46.048980   227 net.cpp:541] norm1 -> norm1\n",
      "I0827 19:12:46.049047   227 net.cpp:259] Setting up norm1\n",
      "I0827 19:12:46.049064   227 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0827 19:12:46.049072   227 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0827 19:12:46.049078   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.049129   227 net.cpp:199] Created Layer pool1 (4)\n",
      "I0827 19:12:46.049141   227 net.cpp:571] pool1 <- norm1\n",
      "I0827 19:12:46.049149   227 net.cpp:541] pool1 -> pool1\n",
      "I0827 19:12:46.049232   227 net.cpp:259] Setting up pool1\n",
      "I0827 19:12:46.049252   227 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0827 19:12:46.049273   227 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0827 19:12:46.049285   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.049314   227 net.cpp:199] Created Layer conv2 (5)\n",
      "I0827 19:12:46.049325   227 net.cpp:571] conv2 <- pool1\n",
      "I0827 19:12:46.049333   227 net.cpp:541] conv2 -> conv2\n",
      "I0827 19:12:46.056489   227 net.cpp:259] Setting up conv2\n",
      "I0827 19:12:46.056516   227 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0827 19:12:46.056536   227 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0827 19:12:46.056550   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.056560   227 net.cpp:199] Created Layer relu2 (6)\n",
      "I0827 19:12:46.056571   227 net.cpp:571] relu2 <- conv2\n",
      "I0827 19:12:46.056586   227 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0827 19:12:46.056608   227 net.cpp:259] Setting up relu2\n",
      "I0827 19:12:46.056624   227 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0827 19:12:46.056636   227 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0827 19:12:46.056646   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.056663   227 net.cpp:199] Created Layer norm2 (7)\n",
      "I0827 19:12:46.056674   227 net.cpp:571] norm2 <- conv2\n",
      "I0827 19:12:46.056684   227 net.cpp:541] norm2 -> norm2\n",
      "I0827 19:12:46.056738   227 net.cpp:259] Setting up norm2\n",
      "I0827 19:12:46.056754   227 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0827 19:12:46.056767   227 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0827 19:12:46.056774   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.056788   227 net.cpp:199] Created Layer pool2 (8)\n",
      "I0827 19:12:46.056799   227 net.cpp:571] pool2 <- norm2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0827 19:12:46.056807   227 net.cpp:541] pool2 -> pool2\n",
      "I0827 19:12:46.056864   227 net.cpp:259] Setting up pool2\n",
      "I0827 19:12:46.056879   227 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0827 19:12:46.056890   227 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0827 19:12:46.056901   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.056921   227 net.cpp:199] Created Layer conv3 (9)\n",
      "I0827 19:12:46.056931   227 net.cpp:571] conv3 <- pool2\n",
      "I0827 19:12:46.056942   227 net.cpp:541] conv3 -> conv3\n",
      "I0827 19:12:46.072911   227 net.cpp:259] Setting up conv3\n",
      "I0827 19:12:46.072938   227 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0827 19:12:46.072954   227 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0827 19:12:46.072968   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.072978   227 net.cpp:199] Created Layer relu3 (10)\n",
      "I0827 19:12:46.072988   227 net.cpp:571] relu3 <- conv3\n",
      "I0827 19:12:46.072996   227 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0827 19:12:46.073011   227 net.cpp:259] Setting up relu3\n",
      "I0827 19:12:46.073024   227 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0827 19:12:46.073029   227 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0827 19:12:46.073040   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.073057   227 net.cpp:199] Created Layer conv4 (11)\n",
      "I0827 19:12:46.073067   227 net.cpp:571] conv4 <- conv3\n",
      "I0827 19:12:46.073074   227 net.cpp:541] conv4 -> conv4\n",
      "I0827 19:12:46.085526   227 net.cpp:259] Setting up conv4\n",
      "I0827 19:12:46.085552   227 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0827 19:12:46.085610   227 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0827 19:12:46.085624   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.085634   227 net.cpp:199] Created Layer relu4 (12)\n",
      "I0827 19:12:46.085646   227 net.cpp:571] relu4 <- conv4\n",
      "I0827 19:12:46.085654   227 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0827 19:12:46.085669   227 net.cpp:259] Setting up relu4\n",
      "I0827 19:12:46.085681   227 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0827 19:12:46.085690   227 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0827 19:12:46.085700   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.085716   227 net.cpp:199] Created Layer conv5 (13)\n",
      "I0827 19:12:46.085726   227 net.cpp:571] conv5 <- conv4\n",
      "I0827 19:12:46.085732   227 net.cpp:541] conv5 -> conv5\n",
      "I0827 19:12:46.093885   227 net.cpp:259] Setting up conv5\n",
      "I0827 19:12:46.093911   227 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0827 19:12:46.093937   227 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0827 19:12:46.093957   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.093972   227 net.cpp:199] Created Layer relu5 (14)\n",
      "I0827 19:12:46.093987   227 net.cpp:571] relu5 <- conv5\n",
      "I0827 19:12:46.093999   227 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0827 19:12:46.094022   227 net.cpp:259] Setting up relu5\n",
      "I0827 19:12:46.094038   227 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0827 19:12:46.094055   227 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0827 19:12:46.094065   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.094089   227 net.cpp:199] Created Layer pool5 (15)\n",
      "I0827 19:12:46.094105   227 net.cpp:571] pool5 <- conv5\n",
      "I0827 19:12:46.094115   227 net.cpp:541] pool5 -> pool5\n",
      "I0827 19:12:46.094192   227 net.cpp:259] Setting up pool5\n",
      "I0827 19:12:46.094213   227 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0827 19:12:46.094224   227 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0827 19:12:46.094240   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.094260   227 net.cpp:199] Created Layer fc6 (16)\n",
      "I0827 19:12:46.094274   227 net.cpp:571] fc6 <- pool5\n",
      "I0827 19:12:46.094283   227 net.cpp:541] fc6 -> fc6\n",
      "I0827 19:12:46.791800   227 net.cpp:259] Setting up fc6\n",
      "I0827 19:12:46.791862   227 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0827 19:12:46.791903   227 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0827 19:12:46.791923   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.791950   227 net.cpp:199] Created Layer relu6 (17)\n",
      "I0827 19:12:46.791968   227 net.cpp:571] relu6 <- fc6\n",
      "I0827 19:12:46.791985   227 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0827 19:12:46.792016   227 net.cpp:259] Setting up relu6\n",
      "I0827 19:12:46.792030   227 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0827 19:12:46.792047   227 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0827 19:12:46.792063   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.792086   227 net.cpp:199] Created Layer drop6 (18)\n",
      "I0827 19:12:46.792098   227 net.cpp:571] drop6 <- fc6\n",
      "I0827 19:12:46.792109   227 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0827 19:12:46.826783   227 net.cpp:259] Setting up drop6\n",
      "I0827 19:12:46.826848   227 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0827 19:12:46.826871   227 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0827 19:12:46.826895   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:46.826926   227 net.cpp:199] Created Layer fc7 (19)\n",
      "I0827 19:12:46.826975   227 net.cpp:571] fc7 <- fc6\n",
      "I0827 19:12:46.826988   227 net.cpp:541] fc7 -> fc7\n",
      "I0827 19:12:47.137791   227 net.cpp:259] Setting up fc7\n",
      "I0827 19:12:47.137845   227 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0827 19:12:47.137867   227 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0827 19:12:47.137887   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:47.137902   227 net.cpp:199] Created Layer relu7 (20)\n",
      "I0827 19:12:47.137917   227 net.cpp:571] relu7 <- fc7\n",
      "I0827 19:12:47.137926   227 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0827 19:12:47.137950   227 net.cpp:259] Setting up relu7\n",
      "I0827 19:12:47.137959   227 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0827 19:12:47.137966   227 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0827 19:12:47.137974   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:47.137989   227 net.cpp:199] Created Layer drop7 (21)\n",
      "I0827 19:12:47.138000   227 net.cpp:571] drop7 <- fc7\n",
      "I0827 19:12:47.138006   227 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0827 19:12:47.172729   227 net.cpp:259] Setting up drop7\n",
      "I0827 19:12:47.172781   227 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0827 19:12:47.172802   227 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0827 19:12:47.172822   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:47.172853   227 net.cpp:199] Created Layer fc8 (22)\n",
      "I0827 19:12:47.172869   227 net.cpp:571] fc8 <- fc7\n",
      "I0827 19:12:47.172886   227 net.cpp:541] fc8 -> fc8\n",
      "I0827 19:12:47.174033   227 net.cpp:259] Setting up fc8\n",
      "I0827 19:12:47.174062   227 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0827 19:12:47.174088   227 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0827 19:12:47.174103   227 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0827 19:12:47.174127   227 net.cpp:199] Created Layer softmax (23)\n",
      "I0827 19:12:47.174139   227 net.cpp:571] softmax <- fc8\n",
      "I0827 19:12:47.174151   227 net.cpp:541] softmax -> softmax\n",
      "I0827 19:12:47.174254   227 net.cpp:259] Setting up softmax\n",
      "I0827 19:12:47.174271   227 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0827 19:12:47.174283   227 net.cpp:337] softmax does not need backward computation.\n",
      "I0827 19:12:47.174294   227 net.cpp:337] fc8 does not need backward computation.\n",
      "I0827 19:12:47.174305   227 net.cpp:337] drop7 does not need backward computation.\n",
      "I0827 19:12:47.174311   227 net.cpp:337] relu7 does not need backward computation.\n",
      "I0827 19:12:47.174322   227 net.cpp:337] fc7 does not need backward computation.\n",
      "I0827 19:12:47.174329   227 net.cpp:337] drop6 does not need backward computation.\n",
      "I0827 19:12:47.174338   227 net.cpp:337] relu6 does not need backward computation.\n",
      "I0827 19:12:47.174345   227 net.cpp:337] fc6 does not need backward computation.\n",
      "I0827 19:12:47.174355   227 net.cpp:337] pool5 does not need backward computation.\n",
      "I0827 19:12:47.174362   227 net.cpp:337] relu5 does not need backward computation.\n",
      "I0827 19:12:47.174372   227 net.cpp:337] conv5 does not need backward computation.\n",
      "I0827 19:12:47.174379   227 net.cpp:337] relu4 does not need backward computation.\n",
      "I0827 19:12:47.174389   227 net.cpp:337] conv4 does not need backward computation.\n",
      "I0827 19:12:47.174396   227 net.cpp:337] relu3 does not need backward computation.\n",
      "I0827 19:12:47.174405   227 net.cpp:337] conv3 does not need backward computation.\n",
      "I0827 19:12:47.174417   227 net.cpp:337] pool2 does not need backward computation.\n",
      "I0827 19:12:47.174428   227 net.cpp:337] norm2 does not need backward computation.\n",
      "I0827 19:12:47.174439   227 net.cpp:337] relu2 does not need backward computation.\n",
      "I0827 19:12:47.174450   227 net.cpp:337] conv2 does not need backward computation.\n",
      "I0827 19:12:47.174461   227 net.cpp:337] pool1 does not need backward computation.\n",
      "I0827 19:12:47.174499   227 net.cpp:337] norm1 does not need backward computation.\n",
      "I0827 19:12:47.174510   227 net.cpp:337] relu1 does not need backward computation.\n",
      "I0827 19:12:47.174520   227 net.cpp:337] conv1 does not need backward computation.\n",
      "I0827 19:12:47.174532   227 net.cpp:337] input does not need backward computation.\n",
      "I0827 19:12:47.174541   227 net.cpp:379] This network produces output softmax\n",
      "I0827 19:12:47.174587   227 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0827 19:12:47.174602   227 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0827 19:12:47.174618   227 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0827 19:12:47.174633   227 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0827 19:12:47.174651   227 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0827 19:12:47.174664   227 net.cpp:420] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0827 19:12:47.306535   227 net.cpp:1129] Ignoring source layer train-data\n",
      "I0827 19:12:47.306578   227 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0827 19:12:47.306707   227 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0827 19:12:47.306725   227 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0827 19:12:47.306733   227 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0827 19:12:47.306746   227 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0827 19:12:47.306977   227 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0827 19:12:47.306993   227 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0827 19:12:47.307001   227 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0827 19:12:47.307014   227 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0827 19:12:47.307595   227 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0827 19:12:47.307610   227 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0827 19:12:47.308045   227 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0827 19:12:47.308059   227 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0827 19:12:47.308363   227 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0827 19:12:47.308377   227 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0827 19:12:47.308382   227 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0827 19:12:47.330906   227 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0827 19:12:47.330950   227 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0827 19:12:47.330958   227 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0827 19:12:47.341051   227 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0827 19:12:47.341092   227 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0827 19:12:47.341099   227 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0827 19:12:47.341140   227 net.cpp:1129] Ignoring source layer loss\n",
      "not whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/not_face/w_1.jpg'  #This should return \"not whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Assessment1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
